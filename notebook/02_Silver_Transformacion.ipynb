{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbcb23aa-928c-452e-b17b-48266fe53ce9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a2ea366-d62b-4dd9-be3a-c70fa664e39b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Procesamiento Capa Silver (fix SyntaxError)"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp, to_date, current_timestamp\n",
    "\n",
    "try:\n",
    "    print(\"â³ Iniciando procesamiento de la Capa Silver...\")\n",
    "    \n",
    "    # 1. LECTURA DE CAPA BRONZE\n",
    "    df_viajes = spark.table(BRONCE_TAXI_TABLE)\n",
    "    \n",
    "    # 2. LIMPIEZA Y NORMALIZACIÃ“N (Idempotencia y Particionado)\n",
    "    print(\"ðŸ§¹ Limpiando y estandarizando datos (Casteos, Filtros y Duplicados)...\")\n",
    "    \n",
    "    df_silver = df_viajes.dropDuplicates([\"hvfhs_license_num\", \"pickup_datetime\",\"Dropoff_datetime\", \"PULocationID\",\"DOLocationID\",\"driver_pay\",\"request_datetime\"]) \\\n",
    "                         .withColumn(\"pickup_datetime\", to_timestamp(col(\"pickup_datetime\"))) \\\n",
    "                         .withColumn(\"dropoff_datetime\", to_timestamp(col(\"dropoff_datetime\"))) \\\n",
    "                         .withColumn(\"pickup_date\", to_date(col(\"pickup_datetime\"))) \\\n",
    "                         .withColumn(\"base_passenger_fare\", col(\"base_passenger_fare\").cast(\"decimal(10,2)\")) \\\n",
    "                         .withColumn(\"tolls\", col(\"tolls\").cast(\"decimal(10,2)\")) \\\n",
    "                         .withColumn(\"sales_tax\", col(\"sales_tax\").cast(\"decimal(10,2)\")) \\\n",
    "                         .withColumn(\"congestion_surcharge\", col(\"congestion_surcharge\").cast(\"decimal(10,2)\")) \\\n",
    "                         .withColumn(\"airport_fee\", col(\"airport_fee\").cast(\"decimal(10,2)\")) \\\n",
    "                         .withColumn(\"tips\", col(\"tips\").cast(\"decimal(10,2)\")) \\\n",
    "                         .withColumn(\"bcf\", col(\"bcf\").cast(\"decimal(10,2)\")) \\\n",
    "                         .filter(col(\"PULocationID\").isNotNull()) \\\n",
    "                         .filter(col(\"dropoff_datetime\") > col(\"pickup_datetime\"))\n",
    "\n",
    "    # 3. ENRIQUECIMIENTO (JOIN con Zonas)\n",
    "    print(\"ðŸ—ºï¸ Enriqueciendo datos con el catÃ¡logo de zonas...\")\n",
    "    \n",
    "    # ValidaciÃ³n: Verificamos si la tabla de zonas existe antes de cruzar\n",
    "    if spark.catalog.tableExists(BRONCE_ZONES_TABLE):\n",
    "        df_zonas = spark.table(BRONCE_ZONES_TABLE)\n",
    "        df_final_silver = df_silver.join(\n",
    "            df_zonas, df_silver.PULocationID == df_zonas.LocationID,\n",
    "            \"left\"\n",
    "        ).select(\n",
    "            df_silver[\"*\"],\n",
    "            col(\"Borough\").alias(\"pickup_borough\"),\n",
    "            col(\"Zone\").alias(\"pickup_zone\")\n",
    "        )\n",
    "    else:\n",
    "        print(f\"âš ï¸ Tabla '{BRONCE_ZONES_TABLE}' no encontrada. Omitiendo JOIN de zonas por ahora.\")\n",
    "        df_final_silver = df_silver\n",
    "\n",
    "    # 4. AUDITORÃA Y PERSISTENCIA (Idempotencia con ReplaceWhere)\n",
    "    df_final_silver = df_final_silver.withColumn(\"silver_processing_timestamp\", current_timestamp())\n",
    "\n",
    "    print(f\"ðŸ’¾ Guardando datos refinados (Idempotente) en la tabla: {SILVER_TAXI_TABLE}...\")\n",
    "    \n",
    "    # Definimos la condiciÃ³n lÃ³gica para la sobreescritura dinÃ¡mica.\n",
    "    # Se deja fijo en esta parte por que sabemos que son datos de un solo mes en produccion real se dejaria variable con los ultimos 60 dia a hoy\n",
    "    condicion_reemplazo = \"pickup_date >= '2025-01-01' AND pickup_date <= '2025-01-31'\"\n",
    "\n",
    "    # Guardamos usando formato Delta, particionando por fecha y reemplazando solo lo necesario\n",
    "    df_final_silver.write.format(\"delta\") \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .option(\"overwriteSchema\", \"true\") \\\n",
    "                .option(\"replaceWhere\", condicion_reemplazo) \\\n",
    "                .partitionBy(\"pickup_date\") \\\n",
    "                .saveAsTable(SILVER_TAXI_TABLE)\n",
    "\n",
    "    print(\"âœ… Capa Silver completada con Ã©xito.\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # 5. GOBIERNO DE DATOS: CONTROL DE SNAPSHOTS Y TIME TRAVEL\n",
    "    # =========================================================================\n",
    "\n",
    "    print(\"ðŸ” Historial de versiones de la tabla Silver:\")\n",
    "    # 1. Ver el historial de todas las operaciones (AuditorÃ­a)\n",
    "    display(spark.sql(f\"DESCRIBE HISTORY {SILVER_TAXI_TABLE}\"))\n",
    "\n",
    "    print(\"\\nâª Consultando una versiÃ³n anterior (Time Travel):\")\n",
    "    # 2. Leer la tabla exactamente como estaba en su VersiÃ³n 0 \n",
    "    df_version_0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).table(SILVER_TAXI_TABLE)\n",
    "    display(df_version_0.limit(5))\n",
    "\n",
    "    # 3. ROLLBACK (Desarrollo Conceptual)\n",
    "    # Si se corrompen los datos, \n",
    "    # usarÃ­amos este comando SQL para restaurar la tabla a un estado saludable:\n",
    "    print(\"\\nðŸ”„ Comando SQL para Rollback ante fallos:\")\n",
    "    print(f\"RESTORE TABLE {SILVER_TAXI_TABLE} TO VERSION AS OF 0;\")\n",
    "    # O restaurar por tiempo: RESTORE TABLE {SILVER_TAXI_TABLE} TO TIMESTAMP AS OF '2025-01-15 10:00:00';\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error en Capa Silver: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5500291208821009,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_Silver_Transformacion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
